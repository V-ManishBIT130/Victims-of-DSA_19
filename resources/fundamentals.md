# DSA Fundamentals

Welcome to the DSA Fundamentals guide! This resource will help you build a strong foundation in Data Structures and Algorithms.

## üìö Table of Contents

1. [What is DSA?](#what-is-dsa)
2. [Why Learn DSA?](#why-learn-dsa)
3. [Basic Data Structures](#basic-data-structures)
4. [Essential Algorithms](#essential-algorithms)
5. [Learning Path](#learning-path)

## What is DSA?

**Data Structures and Algorithms (DSA)** is the study of organizing and processing data efficiently.

- **Data Structures**: Ways to store and organize data
- **Algorithms**: Step-by-step procedures to solve problems

## Why Learn DSA?

### üéØ Key Benefits

1. **Problem Solving**: Develop logical thinking and analytical skills
2. **Efficiency**: Write faster and more memory-efficient code
3. **Interviews**: Essential for technical interviews at top companies
4. **Real-world Applications**: Used in everything from web apps to AI

### üíº Career Impact

- Required for FAANG and top tech companies
- Competitive programming competitions
- Building scalable systems
- Optimizing application performance

## Basic Data Structures

### 1. Arrays
- **Definition**: Collection of elements stored in contiguous memory
- **Operations**: Access, Insert, Delete, Search
- **Time Complexity**: O(1) access, O(n) search
- **Use Cases**: When you need fast access by index

### 2. Linked Lists
- **Definition**: Sequence of nodes connected by pointers
- **Types**: Singly, Doubly, Circular
- **Operations**: Insert, Delete, Traverse
- **Time Complexity**: O(n) access, O(1) insertion/deletion at known position
- **Use Cases**: Dynamic size, frequent insertions/deletions

### 3. Stacks
- **Definition**: LIFO (Last In First Out) structure
- **Operations**: Push, Pop, Peek
- **Time Complexity**: O(1) for all operations
- **Use Cases**: Function calls, undo operations, parsing expressions

### 4. Queues
- **Definition**: FIFO (First In First Out) structure
- **Operations**: Enqueue, Dequeue, Front
- **Time Complexity**: O(1) for all operations
- **Use Cases**: Task scheduling, BFS, message queues

### 5. Trees
- **Definition**: Hierarchical structure with nodes
- **Types**: Binary Tree, BST, AVL, Red-Black
- **Operations**: Insert, Delete, Search, Traverse
- **Use Cases**: File systems, databases, decision making

### 6. Graphs
- **Definition**: Network of nodes (vertices) connected by edges
- **Types**: Directed, Undirected, Weighted
- **Operations**: Add vertex/edge, Remove, Traverse
- **Use Cases**: Social networks, maps, dependencies

### 7. Hash Tables
- **Definition**: Key-value pairs with fast lookup
- **Operations**: Insert, Delete, Search
- **Time Complexity**: O(1) average case
- **Use Cases**: Caching, dictionaries, counting frequencies

## Essential Algorithms

### üîç Searching
- **Linear Search**: O(n) - Check each element
- **Binary Search**: O(log n) - Divide and conquer on sorted data

### üîÑ Sorting
- **Bubble Sort**: O(n¬≤) - Simple but slow
- **Merge Sort**: O(n log n) - Divide and conquer
- **Quick Sort**: O(n log n) average - Fast in practice
- **Heap Sort**: O(n log n) - Uses heap structure

### üå≤ Tree Traversals
- **In-order**: Left ‚Üí Root ‚Üí Right
- **Pre-order**: Root ‚Üí Left ‚Üí Right
- **Post-order**: Left ‚Üí Right ‚Üí Root
- **Level-order**: Breadth-first traversal

### üó∫Ô∏è Graph Algorithms
- **BFS**: Breadth-First Search - Level by level
- **DFS**: Depth-First Search - Go deep first
- **Dijkstra**: Shortest path in weighted graph
- **Kruskal/Prim**: Minimum spanning tree

### üí° Algorithm Techniques
- **Recursion**: Function calling itself
- **Dynamic Programming**: Breaking problems into subproblems
- **Greedy**: Making locally optimal choices
- **Backtracking**: Trying all possibilities
- **Divide and Conquer**: Breaking into smaller problems

## Learning Path

### Phase 1: Foundations (2-3 weeks)
1. Arrays and Strings
2. Basic sorting and searching
3. Time and space complexity
4. Practice 20+ easy problems

### Phase 2: Core Structures (3-4 weeks)
1. Linked Lists, Stacks, Queues
2. Hash Tables
3. Recursion basics
4. Practice 30+ easy-medium problems

### Phase 3: Advanced Structures (4-6 weeks)
1. Trees (Binary Trees, BST)
2. Heaps and Priority Queues
3. Graphs (BFS, DFS)
4. Practice 40+ medium problems

### Phase 4: Algorithms (6-8 weeks)
1. Dynamic Programming
2. Greedy Algorithms
3. Backtracking
4. Advanced graph algorithms
5. Practice 50+ medium-hard problems

### Phase 5: Mastery (Ongoing)
1. System design basics
2. Competitive programming
3. Mock interviews
4. Contribute to open source

## üìñ Recommended Resources

### Books
- "Introduction to Algorithms" by CLRS
- "Cracking the Coding Interview" by Gayle McDowell
- "Algorithm Design Manual" by Steven Skiena

### Online Platforms
- LeetCode
- HackerRank
- CodeChef
- Codeforces

### Video Courses
- MIT OpenCourseWare
- Stanford CS courses
- YouTube channels (Abdul Bari, William Fiset)

## üí™ Practice Tips

1. **Consistency**: Practice daily, even if just 30 minutes
2. **Understand First**: Don't memorize, understand the logic
3. **Multiple Solutions**: Try different approaches
4. **Time Yourself**: Practice under time constraints
5. **Review**: Revisit problems after a few days
6. **Discuss**: Join study groups, discuss solutions

## üéØ Next Steps

1. Start with our [Problem Set](../problems/README.md)
2. Review [Time Complexity Guide](complexity.md)
3. Learn [Common Patterns](patterns.md)
4. Join the Axiom 2025 community!

---

*Created by BIT ISE Team for Axiom 2025*

Happy Learning! üöÄ
